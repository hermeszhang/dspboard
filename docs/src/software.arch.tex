Generic software architecture notes. We really want to separate out
dsp-specific functionality from non-DSP functionality.

\section{Overall software goals}
We want to be able to maintain an indefinite uptime. This means that
we need to work agressively to eliminate problems such as memory
fragmentation in our limited memory space from eventually hurting our
performance. We also investigate the use of watchdog timers to
guarantee and eliminate lost samples.

\subsection{Error handling}
The C++ exception handling features allow us to place our central data
processing loop inside of a try/except statement; when we receive an
exception we serialize it across the event bus.

Fifos should be checked for potential overflow. 

\subsection{Hardware Interfacing}
Our hardware-based IO features include: 
DataOutFifo
EventOutFifo
EventInFifo
SystemTimer()

Signal processing components include: 

Each of these... accesses a DSP singleton object? How does that work? 

\section{The Primary Event Loop}

Our startup sequence goes something like this: 
1. create static DSP(hw) components
2. create IO components
3. create signal processing components
    1. create data sources
    2. create data sinks
    3. create filterlink manager

Then our primary loop is: 
   1. Check and TX output data
   2. check and process input samples
   3. push data for output samples
   4. process N events


\section{Signal Processing}

The DSP signal processing infrastructure is designed to allow the
connection of data sources (such as the continuous data from the
acquisition board) to Data Sinks (like a tetrode packetizer).

These connections occur via signal processing elements called Filter
Links. Our goal here is to be efficient and minimize duplicated
computation and storage. 

Data is produced from Data Sources, which push notification of new
data to FilterLinks. FilterLinks process the data, performing any of a
variety of typical filter operations. Filter links then notify data
sinks when new data is available. Thus all data is ``pushed'' from a
source out the end.

Every item in the FilterLink universe can also send and receive
events and data, and can be constructed independently. At the moment, 
the filter link topology is set at compile-time. 

FIXME: How do we handle the problem of a sink getting data from
multiple sources? I.e. how do we make the tetrode sink realize 
it's gotten data from all four channels as a group? 

\subsection{FilterLinkSource and FilterLinkSink}
FilterLinkSource and FilterLinkSink objects represent
the endpoints of any link, and are loosly based around
existing signalling libraries like Boost::signals and sigc++. 

In particular, you can connect an object's sink to another object's
source, and new data available on that source will trigger
a notification in the sink. 

A source can signal multiple sinks (up to MAXSINKS), but
a sink can only receive data from a single source. 


\subsection{Data Sources}
Each data source can have several input channels of data, these are
associated with SampleBuffers. 


\subsection{Filter Link Manager}
At the moment, this is all built at compile time. 

\subsection{Data Sink}


\section{Metadata and control}
The Soma System is based around the EventBus, a low-latency
high-availability data bus. Devices on the event bus, such as a DSP,
communicate to other devices via the event bus by sending Events to
some subset of other devices.

Each event is six 16-bit big-endian words long, with the first word
consisting of an 8-bit command and an 8-bit source. Every device on
the event bus can place one Event on the bus per ECYCLE (20 us).

Partitoning the range of commands intelligently as the Event space
represents a sort of generic inter-device RPC mechanism, and may be
accessed by all maner of devices: general purpose processors, DSPs,
FPGAs, and devices on the network.


\section{Output} 
There are two types of system output: event and data. Event output
places events on the event bus; Data places data on the data bus.

Note that we can only send one Event per ECYCLE and roughly one Data
packet per ms. Data packets must be less than 600 bytes in length. All
values should be in network byte order, i.e. big-endian. 

For both event and data fifos, you: 

pDp = dataOutFifo.requstNew()
pDp.buffer []
pDp.commit()
